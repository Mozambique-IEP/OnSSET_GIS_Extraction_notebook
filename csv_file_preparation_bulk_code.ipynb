{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GEP-OnSSET GIS-Extraction Notebook for GEP-OnSSET\n",
    "\n",
    "This is the GEP-OnSSET GIS extraction notebook that runs in bulk. \n",
    "\n",
    "There are two options for how to choose the layers: \n",
    " * Choose Option A to browse and select the layer each time.\n",
    " * Choose Option B to enter the paths to each layer, which could go faster if you are trying to run the tool multiple times.\n",
    "\n",
    "For Option B, please provide your layers in the form of **\"../path/filename.ext\"** and run all cell at once. Please make sure the layers are in the proper format and contain the write attributes when needed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Useful hints and common error messages\n",
    "* Make sure that all input layers are using EPSG:4326 as the coordinate system\n",
    "* Make sure that the target \"crs\" is in a coordinate system using meters as the unit\n",
    "* It is often useful to clip all the input layers to the country boundaries in order to reduce processing times\n",
    "* Make sure that each dataset actually has some data within the country boundaries\n",
    "* Some of the datasets require the user to choose values from a dropdown list below\n",
    "* For hydro points and mini-grids, the vector layers need some specific column names to work\n",
    "* In case a dataset still does not work, try opening it in QGIS and run the *Fix geometries* tool and save the new layer.\n",
    "* If things do not work, it may be useful to go to the very top of this Jupyter Notebook and start again from cell 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing necessary packages (Mandatory)\n",
    "\n",
    "Packages to be used are imported from the funcs.ipynb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run funcs.ipynb\n",
    "import traceback\n",
    "import time\n",
    "#import warnings\n",
    "\n",
    "#warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Indicate the layers and parameters to be used\n",
    "\n",
    "## Run either Option A to select all the layers from the File Explorer, or Option B to write all the links instead"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option A\n",
    "\n",
    "First, define the coordinate system (crs). \n",
    "Then select the correct layer each time. If there is a layer you do not have or wish to use, press **Cancel**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crs = 'EPSG:3395'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure this matches the population column in the clusters file\n",
    "x = 'Population'\n",
    "\n",
    "# If you use the hydro layer, make sure the power column and unit match the below\n",
    "hydro_power_column = \"PowerMW\"\n",
    "hydro_power_unit = 'MW'\n",
    "\n",
    "# Select the Admin 1 column if you are using Admin 1 boundaries\n",
    "admin_1_name = \"NAME_1\" #'NAME_1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messagebox.showinfo('OnSSET extraction', 'Output folder')\n",
    "workspace = filedialog.askdirectory()\n",
    "\n",
    "messagebox.showinfo('OnSSET', 'Select the admin boundaries')\n",
    "admin = filedialog.askopenfilename(filetypes = ((\"vector\",[\"*.shp\", \"*.gpkg\", \"*.geojson\"]),(\"all files\",\"*.*\")))\n",
    "\n",
    "messagebox.showinfo('OnSSET', 'Select the clusters')\n",
    "clusters = filedialog.askopenfilename(filetypes = ((\"vector\",[\"*.shp\", \"*.gpkg\", \"*.geojson\"]),(\"all files\",\"*.*\")))\n",
    "\n",
    "\n",
    "## Raster layers\n",
    "messagebox.showinfo('OnSSET', 'Select the Solar GHI layer')\n",
    "ghi_layer = filedialog.askopenfilename(filetypes = ((\"rasters\",\"*.tif\"),(\"all files\",\"*.*\")))\n",
    "\n",
    "messagebox.showinfo('OnSSET', 'Select the Travel Time layer')\n",
    "travel_layer = filedialog.askopenfilename(filetypes = ((\"rasters\",\"*.tif\"),(\"all files\",\"*.*\")))\n",
    "\n",
    "messagebox.showinfo('OnSSET', 'Select the Wind layer')\n",
    "wind_layer = filedialog.askopenfilename(filetypes = ((\"rasters\",\"*.tif\"),(\"all files\",\"*.*\")))\n",
    "\n",
    "messagebox.showinfo('OnSSET', 'Select the Night Lights layer')\n",
    "ntl_layer = filedialog.askopenfilename(filetypes = ((\"rasters\",\"*.tif\"),(\"all files\",\"*.*\")))\n",
    "\n",
    "messagebox.showinfo('OnSSET', 'Select the Custom Demand layer')\n",
    "custDem_layer = filedialog.askopenfilename(filetypes = ((\"rasters\",\"*.tif\"),(\"all files\",\"*.*\")))\n",
    "\n",
    "\n",
    "## Vector Layers\n",
    "\n",
    "messagebox.showinfo('OnSSET', 'Select the Substations layer')\n",
    "sub_layer = filedialog.askopenfilename(filetypes = ((\"vector\",[\"*.shp\", \"*.gpkg\", \"*.geojson\"]),(\"all files\",\"*.*\")))\n",
    "\n",
    "messagebox.showinfo('OnSSET', 'Select the Existing HV layer')\n",
    "HVexist_layer = filedialog.askopenfilename(filetypes = ((\"vector\",[\"*.shp\", \"*.gpkg\", \"*.geojson\"]),(\"all files\",\"*.*\")))\n",
    "\n",
    "messagebox.showinfo('OnSSET', 'Select the Planned HV layer')\n",
    "HVplan_layer = filedialog.askopenfilename(filetypes = ((\"vector\",[\"*.shp\", \"*.gpkg\", \"*.geojson\"]),(\"all files\",\"*.*\")))\n",
    "\n",
    "messagebox.showinfo('OnSSET', 'Select the Existing MV layer')\n",
    "MVexist_layer = filedialog.askopenfilename(filetypes = ((\"vector\",[\"*.shp\", \"*.gpkg\", \"*.geojson\"]),(\"all files\",\"*.*\")))\n",
    "\n",
    "messagebox.showinfo('OnSSET', 'Select the Planned MV layer')\n",
    "MVplan_layer = filedialog.askopenfilename(filetypes = ((\"vector\",[\"*.shp\", \"*.gpkg\", \"*.geojson\"]),(\"all files\",\"*.*\")))\n",
    "\n",
    "messagebox.showinfo('OnSSET', 'Select the Roads layer')\n",
    "road_layer = filedialog.askopenfilename(filetypes = ((\"vector\",[\"*.shp\", \"*.gpkg\", \"*.geojson\"]),(\"all files\",\"*.*\")))\n",
    "\n",
    "messagebox.showinfo('OnSSET', 'Select the Distribution Transformer layer')\n",
    "trx_layer = filedialog.askopenfilename(filetypes = ((\"vector\",[\"*.shp\", \"*.gpkg\", \"*.geojson\"]),(\"all files\",\"*.*\")))\n",
    "\n",
    "## If you use this make sure the hydro layer is a point layer (not a multipoint) and check the column and unit below\n",
    "messagebox.showinfo('OnSSET', 'Select the Hydro layer')\n",
    "hydro_layer = filedialog.askopenfilename(filetypes = ((\"vector\",[\"*.shp\", \"*.gpkg\", \"*.geojson\"]),(\"all files\",\"*.*\")))\n",
    "\n",
    "## If you use this make sure your mini grid layer has these columns 'name', \"MV_network\", \"MG_type\"\n",
    "messagebox.showinfo('OnSSET', 'Select the Mini Grid layer')\n",
    "exist_MG_layer = filedialog.askopenfilename(filetypes = ((\"vector\",[\"*.shp\", \"*.gpkg\", \"*.geojson\"]),(\"all files\",\"*.*\")))\n",
    "\n",
    "messagebox.showinfo('OnSSET', 'Select the Admin 1 layer')\n",
    "adm1_layer = filedialog.askopenfilename(filetypes = ((\"vector\",[\"*.shp\", \"*.gpkg\", \"*.geojson\"]),(\"all files\",\"*.*\")))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option B\n",
    "\n",
    "First, define the coordinate system (crs). \n",
    "Then input the path to each layer. If there is a layer you do not have or wish to use, leave it empty (**''**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#crs = 'EPSG:32737'\n",
    "#workspace = r'C:\\Users\\andre\\Documents\\TrainingMaterial\\ExtractionTest\\Test2'\n",
    "#admin = r\"C:\\Users\\andre\\Documents\\TrainingMaterial\\Scripts\\Input_file_extraction\\Input\\administrative\\gadm36_SLE_0.geojson\"\n",
    "#clusters = r\"C:\\Users\\andre\\Documents\\TrainingMaterial\\Scripts\\Input_file_extraction\\Input\\clusters\\Clusters_SL.gpkg\"\n",
    "\n",
    "# Make sure this matches the population column in the clusters file\n",
    "#x = \"Population\"\n",
    "\n",
    "## Raster layers\n",
    "#ghi_layer = r\"C:\\Users\\andre\\Documents\\TrainingMaterial\\Scripts\\Input_file_extraction\\Input\\GHI\\SL_GHI.tif\"\n",
    "#travel_layer = r\"C:\\Users\\andre\\Documents\\TrainingMaterial\\Scripts\\Input_file_extraction\\Input\\travel_time\\2015_accessibility_to_cities_v1.0_SL.tif\"\n",
    "#wind_layer = r\"C:\\Users\\andre\\Documents\\TrainingMaterial\\Scripts\\Input_file_extraction\\Input\\wind\\WindSpeed.tif\"\n",
    "#ntl_layer = r\"C:\\Users\\andre\\Documents\\TrainingMaterial\\Scripts\\Input_file_extraction\\Input\\ntl\\NightLights.tif\"\n",
    "#custDem_layer = r\"C:\\Users\\andre\\Documents\\TrainingMaterial\\Scripts\\Input_file_extraction\\Input\\customDemand\\CREDIT.tif\"\n",
    "\n",
    "## Vector Layers\n",
    "#sub_layer = r\"C:\\Users\\andre\\Documents\\TrainingMaterial\\Scripts\\Input_file_extraction\\Input\\power_infrastructure\\Transformer_SL.gpkg\"\n",
    "#HVexist_layer = r\"C:\\Users\\andre\\Documents\\TrainingMaterial\\Scripts\\Input_file_extraction\\Input\\power_infrastructure\\HV_existing_SL.gpkg\"\n",
    "#HVplan_layer = r\"C:\\Users\\andre\\Documents\\TrainingMaterial\\Scripts\\Input_file_extraction\\Input\\power_infrastructure\\HV_proposed_SL.gpkg\"\n",
    "#MVexist_layer = r\"C:\\Users\\andre\\Documents\\TrainingMaterial\\Scripts\\Input_file_extraction\\Input\\power_infrastructure\\MV_existing_GridFinder.gpkg\"\n",
    "#MVplan_layer = r\"C:\\Users\\andre\\Documents\\TrainingMaterial\\Scripts\\Input_file_extraction\\Input\\power_infrastructure\\MV_existing_GridFinder.gpkg\"\n",
    "#road_layer = r\"C:\\Users\\andre\\Documents\\TrainingMaterial\\Scripts\\Input_file_extraction\\Input\\roads\\sierra-leone-highway-latest.gpkg\"\n",
    "#trx_layer = r\"C:\\Users\\andre\\Documents\\TrainingMaterial\\Scripts\\Input_file_extraction\\Input\\power_infrastructure\\Transformer_SL.gpkg\"\n",
    "\n",
    "## If you use this make sure the hydro layer is a point layer (not a multipoint) and has a column \"power\" in \"Watts\"\n",
    "#hydro_layer = r\"C:\\Users\\andre\\Documents\\TrainingMaterial\\Scripts\\Input_file_extraction\\Input\\hydropower\\hydro_potential_SL_points.gpkg\"\n",
    "\n",
    "# If you use the hydro layer, make sure the power column and unit match the below\n",
    "#hydro_power_column = \"power\"\n",
    "#hydro_power_unit = 'W'\n",
    "\n",
    "## If you use this make sure your mini grid layer has these columns 'name', \"MV_network\", \"MG_type\"\n",
    "#exist_MG_layer = r\"\"\n",
    "\n",
    "##\n",
    "#adm1_layer = r\"C:\\Users\\andre\\Documents\\TrainingMaterial\\Scripts\\Input_file_extraction\\Input\\administrative\\SL_admin1.gpkg\"\n",
    "#admin_1_name = 'NAME_1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Process layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import admin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "admin = gpd.read_file(admin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = gpd.read_file(clusters)\n",
    "clusters = gpd.clip(clusters, admin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Global Horizontal Irradiation (GHI) from Raster layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    clusters = zonal_stat(ghi_layer, clusters, 'mean', 'GHI')\n",
    "    print(time.ctime()\n",
    "except rasterio.RasterioIOError as e:\n",
    "    print('Could not process solar GHI, or layer was not selected')\n",
    "    print(e)\n",
    "except Exception as e:\n",
    "    traceback.format_exc()\n",
    "    print(traceback.format_exc())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "## Extract Travel Time from Raster layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clusters = processing_raster(\"traveltime\",\"mean\",clusters)\n",
    "try:\n",
    "    clusters = zonal_stat(travel_layer, clusters, 'mean', 'TravelTime')\n",
    "    print(time.ctime()\n",
    "except rasterio.RasterioIOError as e:\n",
    "    print('Could not process Travel Time, or layer was not selected')\n",
    "    print(e)\n",
    "except Exception as e:\n",
    "    traceback.format_exc()\n",
    "    print(traceback.format_exc())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Wind Velocity from Raster layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clusters = processing_raster(\"wind\",\"mean\",clusters)\n",
    "try:\n",
    "    clusters = zonal_stat(wind_layer, clusters, 'mean', 'WindVel')\n",
    "    print(time.ctime()\n",
    "except rasterio.RasterioIOError as e:\n",
    "    print('Could not process Wind velocity, or layer was not selected')\n",
    "    print(e)\n",
    "except Exception as e:\n",
    "    traceback.format_exc()\n",
    "    print(traceback.format_exc())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Night Lights from Raster layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clusters = processing_raster(\"wind\",\"mean\",clusters)\n",
    "try:\n",
    "    clusters = zonal_stat(ntl_layer, clusters, 'max', 'NightLight')\n",
    "    print(time.ctime()\n",
    "except rasterio.RasterioIOError as e:\n",
    "    print('Could not process Wind velocity, or layer was not selected')\n",
    "    print(e)\n",
    "except Exception as e:\n",
    "    traceback.format_exc()\n",
    "    print(traceback.format_exc())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Custom Demand from Raster layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    clusters = zonal_stat(custDem_layer, clusters, 'mean', 'CustomDemand')\n",
    "    print(time.ctime()\n",
    "except rasterio.RasterioIOError as e:\n",
    "    print('Could not process Custom Demand, or layer was not selected')\n",
    "    print(e)\n",
    "except Exception as e:\n",
    "    traceback.format_exc()\n",
    "    print(traceback.format_exc())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing to run the vector data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clusters = preparing_for_vectors(workspace, clusters, crs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Distance from Substations (Vector point layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    clusters = processing_points_bulk(sub_layer, \"Substation\", admin, crs, workspace, clusters, mg_filter=False)\n",
    "except fiona.errors.DriverError as e:\n",
    "    print('Could not process Substations, or layer was not selected')\n",
    "except Exception as e:\n",
    "    traceback.format_exc()\n",
    "    print(traceback.format_exc())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Distance from Existing high voltage lines (Vector line layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    clusters = processing_lines_bulk(HVexist_layer, \"Existing_HV\", admin, crs, workspace, clusters)\n",
    "except fiona.errors.DriverError as e:\n",
    "    print('Could not process Existing HV, or layer was not selected')\n",
    "except Exception as e:\n",
    "    traceback.format_exc()\n",
    "    print(traceback.format_exc())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Distance from Planned high voltage lines (Vector line layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    clusters = processing_lines_bulk(HVplan_layer, \"Planned_HV\", admin, crs, workspace, clusters)\n",
    "except fiona.errors.DriverError as e:\n",
    "    print('Could not process Planned HV, or layer was not selected')\n",
    "    print(e)\n",
    "except Exception as e:\n",
    "    traceback.format_exc()\n",
    "    print(traceback.format_exc())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Distance from Existing medium voltage lines (Vector line layer) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    clusters = processing_lines_bulk(MVexist_layer, \"Existing_MV\", admin, crs, workspace, clusters)\n",
    "except fiona.errors.DriverError as e:\n",
    "    print('Could not process Existing MV, or layer was not selected')\n",
    "    print(e)\n",
    "except Exception as e:\n",
    "    traceback.format_exc()\n",
    "    print(traceback.format_exc())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Distance from Planned medium voltage lines (Vector line layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    clusters = processing_lines_bulk(MVplan_layer, \"Planned_MV\", admin, crs, workspace, clusters)\n",
    "except fiona.errors.DriverError as e:\n",
    "    print('Could not process Planned MV, or layer was not selected')\n",
    "    print(e)\n",
    "except Exception as e:\n",
    "    traceback.format_exc()\n",
    "    print(traceback.format_exc())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Distance from Roads (Vector line layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    clusters = processing_lines_bulk(road_layer, \"Road\", admin, crs, workspace, clusters)\n",
    "except fiona.errors.DriverError as e:\n",
    "    print('Could not process Roads, or layer was not selected')\n",
    "    print(e)\n",
    "except Exception as e:\n",
    "    traceback.format_exc()\n",
    "    print(traceback.format_exc())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Distance from Transformers (Vector point layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    clusters = processing_points_bulk(trx_layer, \"Transformer\", admin, crs, workspace, clusters, mg_filter=False)\n",
    "except fiona.errors.DriverError as e:\n",
    "    print('Could not process Distribution transformers, or layer was not selected')\n",
    "    print(e)\n",
    "except Exception as e:\n",
    "    traceback.format_exc()\n",
    "    print(traceback.format_exc())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Distance from hydro points (Vector point layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    hydro=gpd.read_file(hydro_layer)\n",
    "    clusters = processing_hydro(admin, crs, workspace, clusters, hydro, hydro_power_column, hydro_power_unit)\n",
    "except fiona.errors.DriverError as e:\n",
    "    print('Could not process Hydro, or layer was not selected')\n",
    "    print(e)\n",
    "except Exception as e:\n",
    "    traceback.format_exc()\n",
    "    print(traceback.format_exc())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Distance from Existing ESP (mini-grid) data (Vector point layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    clusters = processing_points_bulk(exist_MG_layer, \"MG\", admin, crs, workspace, clusters, mg_filter=True)\n",
    "except fiona.errors.DriverError as e:\n",
    "    print('Could not process Mini-grids, or layer was not selected')\n",
    "    print(e)\n",
    "except Exception as e:\n",
    "    traceback.format_exc()\n",
    "    print(traceback.format_exc())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding admin 1 name to clusters (Vector polygon layer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    clusters = get_admin1_name_bulk(clusters, adm1_layer, admin_1_name, crs)\n",
    "except fiona.errors.DriverError as e:\n",
    "    print('Could not process Admin_1, or layer was not selected')\n",
    "    print(e)\n",
    "except Exception as e:\n",
    "    traceback.format_exc()\n",
    "    print(traceback.format_exc())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conditioning & Export (Mandatory)\n",
    "\n",
    "This is the final cell in the extraction. This cell has to be run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = create_prio_columns(clusters)\n",
    "clusters = conditioning(clusters, workspace, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
