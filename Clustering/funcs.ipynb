{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "import os\n",
    "from rasterstats import zonal_stats\n",
    "import numpy as np\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog, messagebox\n",
    "import gdal\n",
    "import rasterio\n",
    "import ogr\n",
    "import warnings\n",
    "import json\n",
    "import pandas as pd\n",
    "from earthpy import clip\n",
    "from shapely.geometry import JOIN_STYLE\n",
    "\n",
    "import scipy.spatial\n",
    "from pathlib import Path\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "root = tk.Tk()\n",
    "root.withdraw()\n",
    "root.attributes(\"-topmost\", True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clip raster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clipRaster(raster, polygon, xRes, yRes, output):\n",
    "    kwargs = {'xRes': xRes, 'yRes': yRes, 'dstNodata':0} \n",
    "    warped = gdal.Warp(output, raster, cutlineDSName=polygon, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reclassify raster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reclassifyRasters(file, opt, workspace):\n",
    "    driver = gdal.GetDriverByName(\"GTiff\")\n",
    "    band = file.GetRasterBand(1)\n",
    "    lista = band.ReadAsArray()\n",
    "\n",
    "    for j in range(file.RasterXSize):\n",
    "        for i in range(file.RasterYSize):\n",
    "            if lista[i,j] < 999999999 and lista[i,j] > 0:\n",
    "                lista[i,j] = 1\n",
    "\n",
    "\n",
    "    if opt == 1:\n",
    "        file2 = driver.Create(workspace + r\"/reclassifiedPop.tif\", file.RasterXSize , file.RasterYSize , 1)\n",
    "    else:\n",
    "        file2 = driver.Create(workspace + r\"/reclassifiedNTL.tif\", file.RasterXSize , file.RasterYSize , 1)\n",
    "        \n",
    "    file2.GetRasterBand(1).WriteArray(lista)\n",
    "\n",
    "    proj = file.GetProjection()\n",
    "    georef = file.GetGeoTransform()\n",
    "    file2.SetProjection(proj)\n",
    "    file2.SetGeoTransform(georef)\n",
    "    file2.FlushCache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert raster to polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toPolygon(source, opt, workspace):\n",
    "    sourceRaster = gdal.Open(source)\n",
    "    band = sourceRaster.GetRasterBand(1)\n",
    "    bandArray = band.ReadAsArray()\n",
    "    \n",
    "    if opt == 1:\n",
    "        outShapefile = workspace + r\"\\clusters\"\n",
    "    else:\n",
    "        outShapefile = workspace + r\"\\NTLArea\"\n",
    "        \n",
    "    driver = ogr.GetDriverByName(\"ESRI Shapefile\")\n",
    "\n",
    "\n",
    "    if os.path.exists(outShapefile+\".shp\"):\n",
    "        driver.DeleteDataSource(outShapefile+\".shp\")\n",
    "\n",
    "    outDatasource = driver.CreateDataSource(outShapefile+ \".shp\")\n",
    "\n",
    "    outLayer = outDatasource.CreateLayer(outShapefile+ \".shp\", srs=None)\n",
    "    newField = ogr.FieldDefn('PLACEHOLDER', ogr.OFTInteger)\n",
    "    outLayer.CreateField(newField)\n",
    "    gdal.Polygonize( band, None, outLayer, 0, [], callback=None )\n",
    "    outDatasource.Destroy()\n",
    "    sourceRaster = None\n",
    "    \n",
    "    if opt == 2:\n",
    "        NTLArea=gpd.read_file(workspace + r\"/NTLArea.shp\")\n",
    "        clean = NTLArea[NTLArea.PLACEHOLDE != 0]\n",
    "        clean_b = clean.buffer(0)\n",
    "        clean_b.to_file(workspace + r\"/NTLArea.shp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Buffering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buffer(polygons, workspace):\n",
    "    clusters=gpd.read_file(polygons)\n",
    "    clean = clusters[clusters.PLACEHOLDE != 0]\n",
    "    buffered = clean.buffer(0.001)\n",
    "    convex_hull = buffered.convex_hull\n",
    "    buffered.to_file(workspace + \"/clusters.shp\")\n",
    "    convex_hull = gpd.read_file(workspace + r\"/clusters.shp\")\n",
    "    convex_hull[\"fid\"] = 1\n",
    "    dissolved=convex_hull.dissolve(by=\"fid\")\n",
    "    dissolved.to_file(workspace + r\"/clusters.shp\")\n",
    "    return dissolved"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert multipart ot singlepart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi2single(gpdf):\n",
    "    gpdf_singlepoly = gpdf[gpdf.geometry.type == 'Polygon']\n",
    "    gpdf_multipoly = gpdf[gpdf.geometry.type == 'MultiPolygon']\n",
    "\n",
    "    for i, row in gpdf_multipoly.iterrows():\n",
    "        Series_geometries = pd.Series(row.geometry)\n",
    "        df = pd.concat([gpd.GeoDataFrame(row, crs=gpdf_multipoly.crs).T]*len(Series_geometries), ignore_index=True)\n",
    "        df['geometry']  = Series_geometries\n",
    "        gpdf_singlepoly = pd.concat([gpdf_singlepoly, df])\n",
    "\n",
    "    gpdf_singlepoly.reset_index(inplace=True, drop=True)\n",
    "    return gpdf_singlepoly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dissolve and split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dissolveandsplit(inputfile, crs, filename_admin, country_name, workspace): \n",
    "    inputs = gpd.read_file(inputfile)\n",
    "    eps = 0.001\n",
    "    dissolved = inputs.buffer(eps, 1, join_style=JOIN_STYLE.mitre).buffer(-eps, 1, join_style=JOIN_STYLE.mitre)\n",
    "    dissolved.to_file(workspace + r\"\\clusters.shp\")\n",
    "    dissolved = gpd.read_file(workspace + r\"\\clusters.shp\")\n",
    "\n",
    "    admin = gpd.read_file(filename_admin)\n",
    "    lines = admin.boundary\n",
    "    dissolved_clip = clip.clip_shp(dissolved,admin)\n",
    "    buffered_lines = lines.buffer(0.000000001)\n",
    "    buffered_lines.to_file(workspace + r\"\\bufferedlines.shp\")\n",
    "    buffered_lines = gpd.read_file(workspace + r\"\\bufferedlines.shp\")\n",
    "\n",
    "    clusters = gpd.overlay(dissolved_clip, buffered_lines, how='difference')\n",
    "    clusters = clusters[\"geometry\"] \n",
    "    clusters.to_file(workspace + r\"\\clusters.shp\")\n",
    "    clusters = gpd.read_file(workspace + r\"\\clusters.shp\")\n",
    "    clusters['id'] = np.arange(len(clusters))\n",
    "\n",
    "    clusters.crs = {'init' :'epsg:4326'}\n",
    "    clusters_proj = clusters.to_crs({ 'init': crs})\n",
    "    clusters_proj[\"GridCellAr\"] = clusters_proj.area/1000000\n",
    "    clusters_proj[\"Country\"] = country_name\n",
    "    clusters = clusters_proj.to_crs({ 'init': 'epsg:4326'})\n",
    "    return clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Populating clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def populatingClusters(clusters,raster,column,method):\n",
    "    clusters = zonal_stats(\n",
    "    clusters,\n",
    "    raster.name,\n",
    "    stats=[method],\n",
    "    prefix=column, geojson_out=True, all_touched=True)\n",
    "    \n",
    "    return clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finalizing clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def finalizing_clusters(clusters, workspace):\n",
    "    output = workspace + r'\\placeholder.geojson'\n",
    "    with open(output, \"w\") as dst:\n",
    "        collection = {\n",
    "            \"type\": \"FeatureCollection\",\n",
    "            \"features\": list(clusters)}\n",
    "        dst.write(json.dumps(collection))\n",
    "  \n",
    "    clusters = gpd.read_file(output)\n",
    "    clusters.fillna(0, inplace=True)\n",
    "    os.remove(output)\n",
    "    clusters.to_file(workspace + r\"\\clusters.shp\")\n",
    "\n",
    "    dir_name = workspace\n",
    "    test = os.listdir(dir_name)\n",
    "\n",
    "    for item in test:\n",
    "        if item.endswith(\".tif\") or item.startswith(\"NTLArea\") or item.startswith(\"bufferedlines\"):\n",
    "            os.remove(os.path.join(dir_name, item))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
