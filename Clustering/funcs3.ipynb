{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime as dt\n",
    "import geopandas as gpd\n",
    "import os\n",
    "import fiona\n",
    "import rasterio.mask\n",
    "from rasterio.fill import fillnodata\n",
    "from rasterstats import zonal_stats\n",
    "import numpy as np\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog, messagebox\n",
    "import gdal\n",
    "import rasterio\n",
    "import ogr\n",
    "import warnings\n",
    "import json\n",
    "import pandas as pd\n",
    "from earthpy import clip\n",
    "from shapely.geometry import JOIN_STYLE\n",
    "\n",
    "import scipy.spatial\n",
    "from pathlib import Path\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "root = tk.Tk()\n",
    "root.withdraw()\n",
    "root.attributes(\"-topmost\", True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clip raster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clipRaster(raster, polygon):\n",
    "    kwargs = {'dstNodata':0}\n",
    "    warped = gdal.Warp('', raster, cutlineDSName=polygon, format ='MEM', **kwargs)\n",
    "    return warped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clip and save raster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip_and_save_raster(raster_path, mask_path, crs, workspace):\n",
    "    with fiona.open(mask_path, \"r\") as shapefile:\n",
    "        shapes = [feature[\"geometry\"] for feature in shapefile]\n",
    "    with rasterio.open(raster_path) as src:\n",
    "        out_image, out_transform = rasterio.mask.mask(src, shapes, crop=True)\n",
    "        out_image[out_image<0] = np.nan\n",
    "        mask = (out_image!=0)\n",
    "        out_image = fillnodata(out_image, mask)\n",
    "        out_meta = src.meta\n",
    "    out_meta.update({\"driver\": \"GTiff\",\n",
    "                     \"height\": out_image.shape[1],\n",
    "                     \"width\": out_image.shape[2],\n",
    "                     \"transform\": out_transform,\n",
    "                     \"crs\": crs})\n",
    "    \n",
    "    out_meta.update(compress = 'lzw')\n",
    "    \n",
    "    with rasterio.open(workspace + r\"/elecPop.tif\", \"w\", **out_meta) as dest:\n",
    "        dest.write(out_image)\n",
    "    out = rasterio.open(workspace + r\"/elecPop.tif\")\n",
    "        \n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resample raster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resampleRaster(raster, xRes, yRes):\n",
    "    kwargs = {'xRes': xRes, 'yRes': yRes, 'noData':'0'} \n",
    "    resampled = gdal.Translate('',raster, format ='MEM', **kwargs)\n",
    "    return resampled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reclassify raster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reclassifyRasters(file):    \n",
    "    driver = gdal.GetDriverByName(\"MEM\")\n",
    "    band = file.GetRasterBand(1)\n",
    "    lista = band.ReadAsArray()\n",
    "\n",
    "    lista[np.where((0 < lista) & (lista < 999999999))] = 1\n",
    "\n",
    "    file2 = driver.Create('', file.RasterXSize , file.RasterYSize , 1)\n",
    "    file2.GetRasterBand(1).WriteArray(lista)\n",
    "\n",
    "    proj = file.GetProjection()\n",
    "    georef = file.GetGeoTransform()\n",
    "    file2.SetProjection(proj)\n",
    "    file2.SetGeoTransform(georef)\n",
    "    file2.FlushCache()\n",
    "    \n",
    "    return file2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert raster to polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toPolygon(Raster, opt, workspace):\n",
    "    band = Raster.GetRasterBand(1)\n",
    "    bandArray = band.ReadAsArray()\n",
    "    \n",
    "    if opt == 1:\n",
    "        outShapefile = workspace + r\"\\clusters\"\n",
    "    else:\n",
    "        outShapefile = workspace + r\"\\NTLArea\"\n",
    "    \n",
    "    driver = ogr.GetDriverByName(\"ESRI Shapefile\")\n",
    "    if os.path.exists(outShapefile+\".shp\"):\n",
    "        driver.DeleteDataSource(outShapefile+\".shp\")\n",
    "    outDatasource = driver.CreateDataSource(outShapefile+ \".shp\")\n",
    "    \n",
    "    outLayer = outDatasource.CreateLayer(outShapefile+ \".shp\", srs=None)\n",
    "    newField = ogr.FieldDefn('PLACEHOLDE', ogr.OFTInteger)\n",
    "    outLayer.CreateField(newField)\n",
    "    gdal.Polygonize(band, None, outLayer, 0, [], callback=None )\n",
    "    outDatasource.Destroy()\n",
    "    sourceRaster = None\n",
    "    \n",
    "    if opt == 2:\n",
    "        NTLArea=gpd.read_file(workspace + r\"/NTLArea.shp\")\n",
    "        clean = NTLArea[NTLArea.PLACEHOLDE != 0]\n",
    "        clean_b = clean.buffer(0)\n",
    "        clean_b.crs = {'init' :'epsg:4326'}\n",
    "        clean_b.to_file(workspace + r\"/NTLArea.shp\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save memory raster\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveRaster(raster, workspace):\n",
    "    #Compressing and saving a memory raster layer\n",
    "    kwargs = {'creationOptions': ['COMPRESS=LZW']}\n",
    "    gdal.Warp(workspace + r\"\\elecPop.tif\", raster, **kwargs)\n",
    "    elecPop = rasterio.open(workspace + r\"\\elecPop.tif\")    \n",
    "    return elecPop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Buffering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buffer(polygons, workspace):\n",
    "    #Adds a buffer and dissolves all of the clusters. Convex hull smooths out edges of settlements\n",
    "    clean = polygons[polygons.PLACEHOLDE != 0]\n",
    "    buffered = clean.buffer(0.001)\n",
    "    convex_hull = buffered.convex_hull\n",
    "    envgdf = gpd.GeoDataFrame(gpd.GeoSeries(convex_hull))\n",
    "    envgdf = envgdf.rename(columns={0:'geometry'}).set_geometry('geometry')\n",
    "    envgdf[\"fid\"] = 1\n",
    "    dissolved=envgdf.dissolve(by=\"fid\")\n",
    "    return dissolved"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert multipart ot singlepart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi2single(gpdf, workspace):\n",
    "    #Convert multipart polygons to singlepart polygons\n",
    "    gpdf_singlepoly = gpdf[gpdf.geometry.type == 'Polygon']\n",
    "    gpdf_multipoly = gpdf[gpdf.geometry.type == 'MultiPolygon']\n",
    "\n",
    "    for i, row in gpdf_multipoly.iterrows():\n",
    "        Series_geometries = pd.Series(row.geometry)\n",
    "        df = pd.concat([gpd.GeoDataFrame(row, crs=gpdf_multipoly.crs).T]*len(Series_geometries), ignore_index=True)\n",
    "        df['geometry']  = Series_geometries\n",
    "        gpdf_singlepoly = pd.concat([gpdf_singlepoly, df])\n",
    "\n",
    "    gpdf_singlepoly.reset_index(inplace=True, drop=True)\n",
    "    return gpdf_singlepoly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dissolve and split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dissolveandsplit(inputfile, crs, filename_admin, country_name):\n",
    "    #To make sure all geometries are valid\n",
    "    eps = 0.001\n",
    "    dissolved = inputfile.buffer(eps, 1, join_style=JOIN_STYLE.mitre).buffer(-eps, 1, join_style=JOIN_STYLE.mitre)\n",
    "    envgdf = gpd.GeoDataFrame(gpd.GeoSeries(dissolved))\n",
    "    envgdf = envgdf.rename(columns={0:'geometry'}).set_geometry('geometry')\n",
    "\n",
    "    #For the splitting later\n",
    "    admin = gpd.read_file(filename_admin)\n",
    "    lines = admin.boundary\n",
    "    buffered_lines = lines.buffer(0.000000001)\n",
    "    envgdf2 = gpd.GeoDataFrame(gpd.GeoSeries(buffered_lines))\n",
    "    envgdf2 = envgdf2.rename(columns={0:'geometry'}).set_geometry('geometry')\n",
    "    \n",
    "    #Split and add ids to all rows\n",
    "    clusters = gpd.overlay(envgdf, envgdf2, how='difference')\n",
    "    clusters = clusters[\"geometry\"] \n",
    "    clusters = gpd.GeoDataFrame(gpd.GeoSeries(clusters))\n",
    "    clusters = clusters.rename(columns={0:'geometry'}).set_geometry('geometry')\n",
    "    clusters['id'] = np.arange(len(clusters))\n",
    "    \n",
    "    #Reproject and add country name and cluster Area\n",
    "    clusters.crs = {'init' :'epsg:4326'}\n",
    "    clusters_proj = clusters.to_crs({ 'init': crs})\n",
    "    clusters_proj[\"GridCellAr\"] = clusters_proj.area/1000000\n",
    "    clusters_proj[\"Country\"] = country_name\n",
    "    clusters = clusters_proj.to_crs({ 'init': 'epsg:4326'})\n",
    "    return clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Populating clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def populatingClusters(clusters,raster,column,method):\n",
    "    clusters = zonal_stats(\n",
    "    clusters,\n",
    "    raster.name,\n",
    "    stats=[method],\n",
    "    prefix=column, geojson_out=True, all_touched=True)\n",
    "    \n",
    "    return clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finalizing clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def finalizing_clusters(clusters, workspace):\n",
    "    output = workspace + r'\\placeholder.geojson'\n",
    "    with open(output, \"w\") as dst:\n",
    "        collection = {\n",
    "            \"type\": \"FeatureCollection\",\n",
    "            \"features\": list(clusters)}\n",
    "        dst.write(json.dumps(collection))\n",
    "  \n",
    "    clusters = gpd.read_file(output)\n",
    "    clusters.fillna(0, inplace=True)\n",
    "    os.remove(output)\n",
    "    \n",
    "    clusters = clusters.rename(columns={\"popsum\": \"Pop\"})\n",
    "    clusters = clusters.rename(columns={\"NTLmax\": \"NightLight\"})\n",
    "    clusters = clusters.rename(columns={\"area\": \"GridCellArea\"})\n",
    "    clusters = clusters.rename(columns={\"ElecPopsum\": \"ElecPop\"})\n",
    "    \n",
    "    clusters.to_file(workspace + r\"\\clusters.shp\")\n",
    "\n",
    "    dir_name = workspace\n",
    "    test = os.listdir(dir_name)\n",
    "\n",
    "    for item in test:\n",
    "        if item.endswith(\".tif\") or item.startswith(\"NTLArea\") or item.startswith(\"bufferedlines\"):\n",
    "            os.remove(os.path.join(dir_name, item))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
